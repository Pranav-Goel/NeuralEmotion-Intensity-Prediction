{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code will train our best performing proposed neural model on emotion i, and test on emotion j, as a way to see the pairwise correlation between emotions from the frame of emotion intensity detection task in tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This single code can be used to produce results for all the pairs of emotions, for the correlation test 1 which is emotion i on emotion j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM,Bidirectional,GRU,SimpleRNN\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, merge, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "#tf.python.control_flow_ops = tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose emotions i and j below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_i = 'anger'\n",
    "# emotion_i = 'fear'\n",
    "# emotion_i = 'joy'\n",
    "# emotion_i = 'sadness'\n",
    "\n",
    "# emotion_j = 'anger'\n",
    "emotion_j = 'fear'\n",
    "# emotion_j = 'joy'\n",
    "# emotion_j = 'sadness'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained word2vec based train, dev, and test set tweets representations\n",
    "### Please run the corresponding code in ../Supporting_Codes/ to produce these vector representations.\n",
    "#### Note that these will be vectors of the form (n, l, d) where n is the number of tweets in the set, l is the chosen maximum length (zero padded to have same sequence length = 50 for all samples), and d is the dimensionality of the word embedding (400, since we are using the Twitter word2vec model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_train = np.load('../../intermediate_files/word2vec_based_concatenated_vectors/train/'\n",
    "                   +emotion_i+'.npy')\n",
    "x1_dev = np.load('../../intermediate_files/word2vec_based_concatenated_vectors/dev/'\n",
    "                   +emotion_i+'.npy')\n",
    "\n",
    "'''\n",
    "we combine the train, dev to serve as the training vector. We have already determined the\n",
    "best performing hyperparamter on the dev set, and just need to see results on test set now.\n",
    "'''\n",
    "\n",
    "x1_train = np.concatenate((x1_train,x1_dev),axis=0)\n",
    "\n",
    "x1_test = np.load('../../intermediate_files/word2vec_based_concatenated_vectors/test/'\n",
    "                   +emotion_j+'.npy')\n",
    "\n",
    "print('x1_train shape:', x1_train.shape)    # (n, 50, 400)\n",
    "print('x1_test shape:', x1_test.shape)      # (n, 50, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With reference to Figure 1 in our paper, the above is the first of the parallely connected components. It is the concatenated word2vec representation which can be fed to a CNN/LSTM. \n",
    "\n",
    "### Below, we form the average embedding by simply taking the mean across the words of the sentence (tweet). This can then serve as input to fully connected layers (component 2 in Figure 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2_train = np.mean(x1_train, axis=1)\n",
    "x2_test = np.mean(x1_test, axis=1)\n",
    "\n",
    "print('x2_train shape:', x2_train.shape)    # (n, 400)\n",
    "print('x2_test shape:', x2_test.shape) # (n, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We get the gold labels for our train (=train+dev) and test sets. Note that labels here means the annotated emotion intesities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.concatenate((np.load('../../intermediate_files/gold_label_vectors/train/'\n",
    "                                 +emotion_i+'.npy'),\n",
    "                          np.load('../../intermediate_files/gold_label_vectors/dev/'\n",
    "                                 +emotion_i+'.npy')),axis=0)\n",
    "\n",
    "y_test = np.load('../../intermediate_files/gold_label_vectors/test/'\n",
    "                                 +emotion_j+'.npy')\n",
    "print(y_train.shape)    #(n,)\n",
    "print(y_test.shape)     #(n,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, for the third of the parallely connected components - we combine the deepmoji based pre-trained cnn activations (2304 dim. vector) and our lexicon based features (43 dim. vector). These can be produced by using the corresponding code in ../Supporting_Codes/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x3_train = np.concatenate((np.load('../../intermediate_files/deepmoji_vectors/train/'\n",
    "                                  +emotion_i+'.npy'),\n",
    "                           np.load('../../intermediate_files/lexicon_vectors/train/'\n",
    "                                  +emotion_i+'.npy')), axis=1)\n",
    "x3_dev = np.concatenate((np.load('../../intermediate_files/deepmoji_vectors/dev/'\n",
    "                                  +emotion_i+'.npy'),\n",
    "                           np.load('../../intermediate_files/lexicon_vectors/dev/'\n",
    "                                  +emotion_i+'.npy')), axis=1)\n",
    "x3_train = np.concatenate((x3_train,x3_dev),axis=0)\n",
    "\n",
    "x3_test = np.concatenate((np.load('../../intermediate_files/deepmoji_vectors/test/'\n",
    "                                  +emotion_j+'.npy'),\n",
    "                           np.load('../../intermediate_files/lexicon_vectors/test/'\n",
    "                                  +emotion_j+'.npy')), axis=1)\n",
    "print('x3_train shape:', x3_train.shape)   #(n, 2347)\n",
    "print('x3_test shape:', x3_test.shape)    #(n, 2347)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have the input vectors for each of our three parallely connected components. We can go ahead and train our neural network (per Figure 1). We can output the predictions on the test set, and check the pearson correlation with the actual intensities (done in the cell after).\n",
    "\n",
    "#### Note that we are already using optimized hyperparameter settings. User may tune dropout rate, neurons in dense layers, number of dense layers, etc. on their own, but must do that on validation set (so above code will have training and dev sets and will not make use of test set in that case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.zeros(y_test.shape[0])    #will ultimately contain test set predictions\n",
    "\n",
    "#The results when neural nets like CNNs are involved can vary by a bit on every run.\n",
    "#To account for that, we train and predict 7 times, and take mean to get our final predictions\n",
    "for i in range(7) : \n",
    "    print('Iteration ',i+1)\n",
    "    \n",
    "    # Same architecture is used for all emotions\n",
    "    \n",
    "    #Component 1 - CNN\n",
    "    \n",
    "    input1 = Input(shape=(50,400,))\n",
    "    l1 = Conv1D(128,3,activation='relu')(input1)\n",
    "    #l2 = Conv1D(64,3,activation='relu')(l2)\n",
    "    l1 = GlobalMaxPooling1D()(l1)\n",
    "    l1 = Dropout(p=0.2)(l1)\n",
    "    l1 = Dense(128,activation='relu')(l1)\n",
    "    #l2 = Dense(50,activation='relu')(l2)\n",
    "    #l2 = Dense(25,activation='relu')(l2)\n",
    "    #o2 = Dense(1)(l2)\n",
    "    \n",
    "    #Component 2 - Fully connected layers on average embedding\n",
    "    \n",
    "    input2 = Input(shape=(400,))\n",
    "    l2 = Dense(256, init='normal', activation='relu')(input2)\n",
    "    l2 = Dropout(p=0.2)(l2)\n",
    "    l2 = Dense(128, init='normal', activation='relu')(l2)\n",
    "    #l1 = Dense(50, init='normal', activation='relu')(l1)\n",
    "    #l1 = Dropout(p=0.2)(l1)\n",
    "    #l1 = Dense(25, init='normal', activation='relu')(l1)\n",
    "    #o1 = Dense(1, init='normal')(l1)\n",
    "    \n",
    "    #Component 3 - ('LE') Lexicon and deepmoji (Emoji) based feature vector\n",
    "\n",
    "    input3 = Input(shape=(2347,))\n",
    "    \n",
    "    \n",
    "    # Combining the 3 components - 'Parallely Connected' DNN\n",
    "    \n",
    "    merged_output = merge([l1, l2, input3], mode='concat', concat_axis=-1)\n",
    "    \n",
    "    #sequentially connected fully-connected layers on top (component 4)\n",
    "    \n",
    "    merged_output = Dense(128, activation='relu')(merged_output)\n",
    "    merged_output = Dropout(p=0.2)(merged_output)\n",
    "    merged_output = Dense(64, activation='relu')(merged_output)\n",
    "    merged_output = Dense(32, activation='relu')(merged_output)\n",
    "    merged_output = Dropout(p=0.2)(merged_output)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merged_output)\n",
    "\n",
    "    model = Model(input=[input1, input2, input3], output=predictions)\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=['mae'])# metrics=[pearson])\n",
    "    \n",
    "    model.fit([x1_train, x2_train, x3_train], y_train, \n",
    "              nb_epoch=25, batch_size=8, verbose=0) #set the verbose value according to your needs\n",
    "    \n",
    "    tmp = model.predict([x1_test, x2_test, x3_test]) #temporary predictions for each iteration\n",
    "    #print(pearsonr(tmp[:,0], label_test))\n",
    "    y_pred += tmp[:,0]    #Add to the final prediction vector\n",
    "    \n",
    "    print('Iteration ',i+1,' Done')\n",
    "    \n",
    "y_pred = y_pred/7.0    #Final predictions\n",
    "print('Training DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pearson_correlation_score = pearsonr(y_pred, y_test)[0]\n",
    "\n",
    "print('Pearson Correlation for full model for Training on emotion '+emotion_i+' and Testing on emotion '+emotion_j)\n",
    "print(pearson_correlation_score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
